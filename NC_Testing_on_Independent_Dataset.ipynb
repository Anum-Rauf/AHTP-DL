{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NC-Testing on Independent Dataset.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "oxFvcpDSTR4m",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "28ee2fd3-7f57-44e2-a115-55fe9facbd53"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j5caLLHJTdrE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# In following sections, the g-gap features are further processed to test CNN\n",
        "c=\"/content/drive/My Drive/Colab Notebooks/allseq_ind.csv\"\n",
        "with open(c) as f:\n",
        "    content = f.read() \n",
        "s=0\n",
        "dat=content.split(\"\\n\") \n",
        "for i in dat:\n",
        "    dat[s]=list(dat[s])\n",
        "    s=s+1\n",
        "          \n",
        "\n",
        "    \n",
        "import numpy as np\n",
        "lm=1\n",
        "tp=np.zeros(772)\n",
        "for h in range(772):\n",
        "    tp[h]=len(dat[lm])\n",
        "    lm=lm+2\n",
        "#%%\n",
        "c=\"/content/drive/My Drive/Colab Notebooks/zero_ind.csv\"\n",
        "with open(c) as f:\n",
        "    content0 = f.read() \n",
        "    \n",
        "dat0=content0.split(\"\\n\") \n",
        "s=0\n",
        "for i in range(len(dat0)):\n",
        "    dat0[s]=dat0[s].split(\",\")\n",
        "    s=s+1\n",
        "    \n",
        "   \n",
        "import numpy as np\n",
        "dataaa0=np.zeros((772,400))\n",
        "ii=0; jj=0\n",
        "for i in range(772):\n",
        "    for j in range(400):\n",
        "        dataaa0[i][j]=float(dat0[i][j])\n",
        "        \n",
        "tc=0\n",
        "for i in range(772):\n",
        "    tc=tp[i]-1\n",
        "    dataaa0[i]=dataaa0[i]*tc\n",
        "    \n",
        "#%%\n",
        "c=\"/content/drive/My Drive/Colab Notebooks/one_ind.csv\"\n",
        "with open(c) as f:\n",
        "    content1 = f.read() \n",
        "    \n",
        "dat1=content1.split(\"\\n\") \n",
        "s=0\n",
        "for i in range(len(dat1)):\n",
        "    dat1[s]=dat1[s].split(\",\")\n",
        "    s=s+1\n",
        "    \n",
        "   \n",
        "import numpy as np\n",
        "dataaa1=np.zeros((772,400))\n",
        "ii=0; jj=0\n",
        "for i in range(772):\n",
        "    for j in range(400):\n",
        "        dataaa1[i][j]=float(dat1[i][j])\n",
        "        \n",
        "tc=0\n",
        "for i in range(772):\n",
        "    tc=tp[i]-1\n",
        "    dataaa1[i]=dataaa1[i]*tc\n",
        "    \n",
        "#%%\n",
        "c=\"/content/drive/My Drive/Colab Notebooks/two_ind.csv\"\n",
        "with open(c) as f:\n",
        "    content2 = f.read() \n",
        "    \n",
        "dat2=content2.split(\"\\n\") \n",
        "s=0\n",
        "for i in range(len(dat2)):\n",
        "    dat2[s]=dat2[s].split(\",\")\n",
        "    s=s+1\n",
        "    \n",
        "   \n",
        "import numpy as np\n",
        "dataaa2=np.zeros((772,400))\n",
        "ii=0; jj=0\n",
        "for i in range(772):\n",
        "    for j in range(400):\n",
        "        dataaa2[i][j]=float(dat2[i][j])\n",
        "        \n",
        "tc=0\n",
        "for i in range(772):\n",
        "    tc=tp[i]-1\n",
        "    dataaa2[i]=dataaa2[i]*tc\n",
        "#%%\n",
        "c=\"/content/drive/My Drive/Colab Notebooks/three_ind.csv\"\n",
        "with open(c) as f:\n",
        "    content3 = f.read() \n",
        "    \n",
        "dat3=content3.split(\"\\n\") \n",
        "s=0\n",
        "for i in range(len(dat3)):\n",
        "    dat3[s]=dat3[s].split(\",\")\n",
        "    s=s+1\n",
        "    \n",
        "   \n",
        "import numpy as np\n",
        "dataaa3=np.zeros((772,400))\n",
        "ii=0; jj=0\n",
        "for i in range(772):\n",
        "    for j in range(400):\n",
        "        dataaa3[i][j]=float(dat3[i][j])\n",
        "        \n",
        "tc=0\n",
        "for i in range(772):\n",
        "    tc=tp[i]-1\n",
        "    dataaa3[i]=dataaa3[i]*tc "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qe21T3wcloUU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "a = np.reshape(dataaa0,[772,20,20])\n",
        "b = np.reshape(dataaa1,[772,20,20])\n",
        "c = np.reshape(dataaa2,[772,20,20])\n",
        "feature1=np.zeros((772,20,20,3))\n",
        "for i in range(772):\n",
        "  data = np.zeros( (20,20,3))\n",
        "  data[:,:,0]=a[i,:,:]\n",
        "  data[:,:,1]=b[i,:,:]\n",
        "  data[:,:,2]=c[i,:,:]\n",
        "  feature1[i]=data                \n",
        "                  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v6jw9cRFT5ft",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "a = np.reshape(dataaa0,[772,20,20])\n",
        "b = np.reshape(dataaa1,[772,20,20])\n",
        "c = np.reshape(dataaa3,[772,20,20])\n",
        "feature2=np.zeros((772,20,20,3))\n",
        "for i in range(772):\n",
        "  data = np.zeros( (20,20,3))\n",
        "  data[:,:,0]=a[i,:,:]\n",
        "  data[:,:,1]=b[i,:,:]\n",
        "  data[:,:,2]=c[i,:,:]\n",
        "  feature2[i]=data "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ePRsSm3elvEm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "a = np.reshape(dataaa0,[772,20,20])\n",
        "b = np.reshape(dataaa2,[772,20,20])\n",
        "c = np.reshape(dataaa3,[772,20,20])\n",
        "feature3=np.zeros((772,20,20,3))\n",
        "for i in range(772):\n",
        "  data = np.zeros( (20,20,3))\n",
        "  data[:,:,0]=a[i,:,:]\n",
        "  data[:,:,1]=b[i,:,:]\n",
        "  data[:,:,2]=c[i,:,:]\n",
        "  feature3[i]=data                \n",
        "                  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BcnqaR4BlykJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "a = np.reshape(dataaa1,[772,20,20])\n",
        "b = np.reshape(dataaa2,[772,20,20])\n",
        "c = np.reshape(dataaa3,[772,20,20])\n",
        "feature4=np.zeros((772,20,20,3))\n",
        "for i in range(772):\n",
        "  data = np.zeros( (20,20,3))\n",
        "  data[:,:,0]=a[i,:,:]\n",
        "  data[:,:,1]=b[i,:,:]\n",
        "  data[:,:,2]=c[i,:,:]\n",
        "  feature4[i]=data     "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "--WrtI6Rl2kT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "label=np.zeros(772)\n",
        "for i in range(386):\n",
        "    label[i]=0\n",
        "j=386  \n",
        "for k in range(386):\n",
        "    label[j]=1\n",
        "    j=j+1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "63clBoEDdExJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "12e4be56-8969-4cce-b62f-d9fa4846f0d2"
      },
      "source": [
        "import os,cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from keras import backend as K\n",
        "K.set_image_data_format('channels_last')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "from keras.utils import np_utils\n",
        "from keras.models import Sequential\n",
        "from keras.layers  import Dense, Dropout, Activation, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "!pip install adam\n",
        "import adam\n",
        "from keras.optimizers import SGD,RMSprop\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "import numpy\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting adam\n",
            "  Downloading https://files.pythonhosted.org/packages/1f/80/f822a29a54098e22cee0131fa67ad4902106e576c5096e12a7bb11845f16/adam-0.0.0.dev0-py2.py3-none-any.whl\n",
            "Installing collected packages: adam\n",
            "Successfully installed adam-0.0.0.dev0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GbiF4k5kl5ZE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "outputId": "cb325607-41f8-42e5-eda2-d7f685ca8cbc"
      },
      "source": [
        "filepath=\"/content/drive/My Drive/Colab Notebooks/new-weights-bench-cv10-0,1,2-NC-2.hdf5\" #.............................\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, (3, 3),  input_shape=feature1[0].shape)) #............................\n",
        "convout1 = Activation('relu')\n",
        "model.add(convout1)\n",
        "convout3 = Activation('relu')\n",
        "model.add(convout3)\n",
        "model.add(Conv2D(8,( 3, 3)))\n",
        "  \n",
        "model.add(MaxPooling2D(pool_size=(2,2 )))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(170))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(1))\n",
        "model.add(Activation('sigmoid'))\n",
        "\n",
        "#model.compile(loss='binary_crossentropy', optimizer='adam', metrics=[\"accuracy\"])\n",
        "# load weights\n",
        "model.load_weights(filepath)\n",
        "# Compile model (required to make predictions)\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=[\"accuracy\"])\n",
        "print(\"Created model and loaded weights from file\")\n",
        "# load pima indians dataset\n",
        "p1=model.predict_classes(feature1) #................\n",
        "#pre.apppend(t1)\n",
        "from sklearn.metrics import confusion_matrix\n",
        "cm1 = confusion_matrix(label, p1)#...............................\n",
        "print(cm1)\n",
        "total1=sum(sum(cm1))\n",
        "accuracy1=(cm1[0,0]+cm1[1,1])/total1\n",
        "print(accuracy1)\n",
        "scores = model.evaluate(feature1, label, verbose=0)#.............................\n",
        "print(scores)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Created model and loaded weights from file\n",
            "WARNING:tensorflow:From <ipython-input-10-1abefa524a1c>:27: Sequential.predict_classes (from tensorflow.python.keras.engine.sequential) is deprecated and will be removed after 2021-01-01.\n",
            "Instructions for updating:\n",
            "Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "[[280 106]\n",
            " [ 53 333]]\n",
            "0.7940414507772021\n",
            "[3.1573245525360107, 0.7940414547920227]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tjy2LSulrRUx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "4e6c1287-02a4-4682-ef03-af35e58461a4"
      },
      "source": [
        "filepath=\"/content/drive/My Drive/Colab Notebooks/new-weights-bench-cv10-0,1,3-NC-2.hdf5\" #.............................\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, (3, 3),  input_shape=feature2[0].shape)) #............................\n",
        "convout1 = Activation('relu')\n",
        "model.add(convout1)\n",
        "convout3 = Activation('relu')\n",
        "model.add(convout3)\n",
        "model.add(Conv2D(8,( 3, 3)))\n",
        "  \n",
        "model.add(MaxPooling2D(pool_size=(2,2 )))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(170))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(1))\n",
        "model.add(Activation('sigmoid'))\n",
        "\n",
        "#model.compile(loss='binary_crossentropy', optimizer='adam', metrics=[\"accuracy\"])\n",
        "# load weights\n",
        "model.load_weights(filepath)\n",
        "# Compile model (required to make predictions)\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=[\"accuracy\"])\n",
        "print(\"Created model and loaded weights from file\")\n",
        "# load pima indians dataset\n",
        "p2=model.predict_classes(feature2) #................\n",
        "#pre.apppend(t1)\n",
        "from sklearn.metrics import confusion_matrix\n",
        "cm1 = confusion_matrix(label, p2)#...............................\n",
        "print(cm1)\n",
        "total1=sum(sum(cm1))\n",
        "accuracy1=(cm1[0,0]+cm1[1,1])/total1\n",
        "print(accuracy1)\n",
        "scores = model.evaluate(feature2, label, verbose=0)#.............................\n",
        "print(scores)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Created model and loaded weights from file\n",
            "[[259 127]\n",
            " [ 48 338]]\n",
            "0.7733160621761658\n",
            "[3.298546552658081, 0.7733160853385925]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1MrwO3QHrRkj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "6f566469-3a2d-4311-cd1a-73ad8c84c920"
      },
      "source": [
        "filepath=\"/content/drive/My Drive/Colab Notebooks/new-weights-bench-cv10-0,2,3-NC-2.hdf5\" #.............................\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, (3, 3),  input_shape=feature3[0].shape)) #............................\n",
        "convout1 = Activation('relu')\n",
        "model.add(convout1)\n",
        "convout3 = Activation('relu')\n",
        "model.add(convout3)\n",
        "model.add(Conv2D(8,( 3, 3)))\n",
        "  \n",
        "model.add(MaxPooling2D(pool_size=(2,2 )))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(170))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(1))\n",
        "model.add(Activation('sigmoid'))\n",
        "\n",
        "#model.compile(loss='binary_crossentropy', optimizer='adam', metrics=[\"accuracy\"])\n",
        "# load weights\n",
        "model.load_weights(filepath)\n",
        "# Compile model (required to make predictions)\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=[\"accuracy\"])\n",
        "print(\"Created model and loaded weights from file\")\n",
        "# load pima indians dataset\n",
        "p3=model.predict_classes(feature3) #................\n",
        "#pre.apppend(t1)\n",
        "from sklearn.metrics import confusion_matrix\n",
        "cm1 = confusion_matrix(label, p3)#...............................\n",
        "print(cm1)\n",
        "total1=sum(sum(cm1))\n",
        "accuracy1=(cm1[0,0]+cm1[1,1])/total1\n",
        "print(accuracy1)\n",
        "scores = model.evaluate(feature3, label, verbose=0)#.............................\n",
        "print(scores)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Created model and loaded weights from file\n",
            "[[235 151]\n",
            " [ 51 335]]\n",
            "0.7383419689119171\n",
            "[3.506981134414673, 0.7383419871330261]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "syb9WpocrSXU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "217f84c4-52f1-4caa-8249-b63c962c704a"
      },
      "source": [
        "filepath=\"/content/drive/My Drive/Colab Notebooks/new-weights-bench-cv10-1,2,3-NC-2.hdf5\" #.............................\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, (3, 3),  input_shape=feature4[0].shape)) #............................\n",
        "convout1 = Activation('relu')\n",
        "model.add(convout1)\n",
        "convout3 = Activation('relu')\n",
        "model.add(convout3)\n",
        "model.add(Conv2D(8,( 3, 3)))\n",
        "  \n",
        "model.add(MaxPooling2D(pool_size=(2,2 )))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(170))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(1))\n",
        "model.add(Activation('sigmoid'))\n",
        "\n",
        "#model.compile(loss='binary_crossentropy', optimizer='adam', metrics=[\"accuracy\"])\n",
        "# load weights\n",
        "model.load_weights(filepath)\n",
        "# Compile model (required to make predictions)\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=[\"accuracy\"])\n",
        "print(\"Created model and loaded weights from file\")\n",
        "# load pima indians dataset\n",
        "p4=model.predict_classes(feature4) #................\n",
        "#pre.apppend(t1)\n",
        "from sklearn.metrics import confusion_matrix\n",
        "cm1 = confusion_matrix(label, p4)#...............................\n",
        "print(cm1)\n",
        "total1=sum(sum(cm1))\n",
        "accuracy1=(cm1[0,0]+cm1[1,1])/total1\n",
        "print(accuracy1)\n",
        "scores = model.evaluate(feature4, label, verbose=0)#.............................\n",
        "print(scores)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Created model and loaded weights from file\n",
            "[[261 125]\n",
            " [ 49 337]]\n",
            "0.7746113989637305\n",
            "[2.468719959259033, 0.7746114134788513]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Nx6mAjel-SE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "featureee=np.zeros((772,4))\n",
        "for i in range(772):\n",
        "  featureee[i,0]=p1[i]\n",
        "  featureee[i,1]=p2[i]\n",
        "  featureee[i,2]=p3[i]\n",
        "  featureee[i,3]=p4[i]\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bmNUNDwkmCOk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "96d5efea-4b7d-4da8-b2bb-399e8248cdd8"
      },
      "source": [
        "c=\"/content/drive/My Drive/Colab Notebooks/allseq_ind.csv\"\n",
        "with open(c) as f:\n",
        "    content = f.read() \n",
        "s=0\n",
        "dat=content.split(\"\\n\") \n",
        "for i in dat:\n",
        "    dat[s]=list(dat[s])\n",
        "    s=s+1\n",
        "import numpy as np    \n",
        "feature = np.zeros((772,20,))\n",
        "print(feature)  \n",
        "ppp=20\n",
        "aa=0; rr=0; nn=0; dd=0; cc=0; qq=0; ee=0; gg=0; hh=0; ii=0; ll=0; kk=0; mm=0; ff=0; pp=0; ss=0; tt=0; ww=0; yy=0; vv=0; \n",
        "sss=0;\n",
        "spsp=1;\n",
        "\n",
        "\n",
        "for i in range(772):\n",
        "    word = dat[spsp]\n",
        "    v=0\n",
        "    for l in word:\n",
        "        if word[v]=='A':\n",
        "            aa=aa+1\n",
        "        elif word[v]=='R':\n",
        "            rr=rr+1\n",
        "        elif word[v]=='N':\n",
        "            nn=nn+1\n",
        "        elif word[v]=='D':\n",
        "            dd=dd+1\n",
        "        elif word[v]=='C':\n",
        "            cc=cc+1\n",
        "        elif word[v]=='Q':\n",
        "            qq=qq+1\n",
        "        elif word[v]=='E':\n",
        "            ee=ee+1\n",
        "        elif word[v]=='G':\n",
        "            gg=gg+1\n",
        "        elif word[v]=='H':\n",
        "            hh=hh+1\n",
        "        elif word[v]=='I':\n",
        "            ii=ii+1\n",
        "        elif word[v]=='L':\n",
        "            ll=ll+1\n",
        "        elif word[v]=='K':\n",
        "            kk=kk+1\n",
        "        elif word[v]=='M':\n",
        "            mm=mm+1\n",
        "        elif word[v]=='F':\n",
        "            ff=ff+1\n",
        "        elif word[v]=='P':\n",
        "            pp=pp+1\n",
        "        elif word[v]=='S':\n",
        "            ss=ss+1\n",
        "        elif word[v]=='T':\n",
        "            tt=tt+1\n",
        "        elif word[v]=='W':\n",
        "            ww=ww+1\n",
        "        elif word[v]=='Y':\n",
        "            yy=yy+1\n",
        "        else:\n",
        "            vv=vv+1\n",
        "        v=v+1    \n",
        "    \n",
        "    #aa=aa/20; rr=rr/20; nn=nn/20; dd=dd/20; cc=cc/20; qq=qq/20; ee=ee/20; gg=gg/20; hh=hh/20; ii=ii/20; ll=ll/20; kk=kk/20; mm=mm/20; ff=ff/20; pp=pp/20; ss=ss/20; tt=tt/20; ww=ww/20; yy=yy/20; vv=vv/20;\n",
        "    feature[sss][0]=aa; feature[sss][1]=rr; feature[sss][2]=nn; feature[sss][3]=dd; feature[sss][4]=cc; feature[sss][5]=qq; feature[sss][6]=ee; feature[sss][7]=gg; feature[sss][8]=hh; feature[sss][9]=ii; feature[sss][10]=ll; feature[sss][11]=kk; feature[sss][12]=mm; feature[sss][13]=ff; feature[sss][14]=pp; feature[sss][15]=ss; feature[sss][16]=tt; feature[sss][17]=ww; feature[sss][18]=yy; feature[sss][19]=vv; \n",
        "    aa=0; rr=0; nn=0; dd=0; cc=0; qq=0; ee=0; gg=0; hh=0; ii=0; ll=0; kk=0; mm=0; ff=0; pp=0; ss=0; tt=0; ww=0; yy=0; vv=0;\n",
        "    sss=sss+1\n",
        "    spsp=spsp+2"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " ...\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fkhKLGh0mIRc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "inputt=np.zeros((772,24))\n",
        "inputt[:,0:4]=featureee[:,:]\n",
        "inputt[:,4:]=feature[:,:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y4gOcxVomMKP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b81b63ae-7245-4634-cc4a-d4abe081257e"
      },
      "source": [
        "import pickle\n",
        "filename='/content/drive/My Drive/Colab Notebooks/new-svm-benc10-NC-4.sav'\n",
        "loaded_model = pickle.load(open(filename, 'rb'))\n",
        "result = loaded_model.score(inputt, label)\n",
        "result1=loaded_model.predict(inputt)\n",
        "print(result)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.8950777202072538\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r2e82ZwLmRYT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "19fe93e0-8adc-4ff2-ed58-206018578263"
      },
      "source": [
        "cm1 = confusion_matrix(label, result1)\n",
        "sensitivity1 = cm1[0,0]/(cm1[0,0]+cm1[0,1])\n",
        "print('Sensitivity : ', sensitivity1 )\n",
        "\n",
        "specificity1 = cm1[1,1]/(cm1[1,0]+cm1[1,1])\n",
        "print('Specificity : ', specificity1)\n",
        "tp=cm1[0,0]\n",
        "print('tp : ', tp)\n",
        "fp=cm1[0,1]\n",
        "print('fp : ', fp)\n",
        "fn=cm1[1,0]\n",
        "print('fn : ', fn)\n",
        "tn=cm1[1,0]\n",
        "print('tn : ', tn)\n",
        "#%%\n",
        "from sklearn.metrics import matthews_corrcoef\n",
        "mcc = matthews_corrcoef(label,result1)\n",
        "print('Matthews Correlation Coefficient:', mcc)\n",
        "\n",
        "  #%%\n",
        "total1=sum(sum(cm1))\n",
        "\n",
        "accuracy1=(cm1[0,0]+cm1[1,1])/total1\n",
        "print ('Accuracy : ', accuracy1)\n",
        "\n",
        "import numpy as np\n",
        "from sklearn import metrics\n",
        "fpr, tpr, thresholds = metrics.roc_curve(label, result1)\n",
        "aucc=metrics.auc(fpr, tpr)\n",
        "print('AUC:', aucc)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sensitivity :  0.9481865284974094\n",
            "Specificity :  0.8419689119170984\n",
            "tp :  366\n",
            "fp :  20\n",
            "fn :  61\n",
            "tn :  61\n",
            "Matthews Correlation Coefficient: 0.7946508537062464\n",
            "Accuracy :  0.8950777202072538\n",
            "AUC: 0.8950777202072538\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mPU8unNymW3c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}